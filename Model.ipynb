{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smuzka/SSN-project/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zespół 4:\n",
        "- Jakub Smuga\n",
        "- Konrad Korus\n",
        "- Maksym Kazhaiev"
      ],
      "metadata": {
        "id": "mkAqDGoQ0JKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Podział danych"
      ],
      "metadata": {
        "id": "5yCNizYv0zbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "QfVkstAb4oAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_shuffle_state = 2024\n",
        "\n",
        "def train_valid_test_split(features, targets, valid_p = 0.1, test_p = 0.3):\n",
        "  # shuffle the features and targets in the same way\n",
        "  features = shuffle(features, random_state = random_shuffle_state)\n",
        "  targets = shuffle(targets, random_state = random_shuffle_state)\n",
        "  train_size = int(len(features) * (1 - (test_p + valid_p)))\n",
        "  valid_size = int(len(features) * valid_p)\n",
        "\n",
        "  X_train, X_valid, X_test = features[:train_size], features[train_size:train_size + valid_size], features[train_size + valid_size:]\n",
        "  y_train, y_valid, y_test = targets[:train_size], targets[train_size:train_size + valid_size], targets[train_size + valid_size:]\n",
        "  return (X_train, y_train, X_valid, y_valid, X_test, y_test)"
      ],
      "metadata": {
        "id": "mQDOe95_0zi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "qFucwhtl33px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "os7I8rdb32Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8ymBqMtF04rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funkcja ucząca model"
      ],
      "metadata": {
        "id": "tGqcDfG85ibO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train_tensor, y_train_tensor, X_valid_tensor, y_valid_tensor):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(X_train_tensor), batch_size):\n",
        "            inputs = X_train_tensor[i:i+batch_size]\n",
        "            labels = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Compute and print training accuracy\n",
        "        with torch.no_grad():\n",
        "            outputs = model(X_train_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_accuracy = (predicted == y_train_tensor).sum().item() / len(y_train_tensor)\n",
        "\n",
        "            # Compute and print test accuracy\n",
        "            outputs = model(X_valid_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            valid_accuracy = (predicted == y_valid_tensor).sum().item() / len(y_valid_tensor)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "JVbC_kRUAfQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pobieranie danych"
      ],
      "metadata": {
        "id": "omfqXa1s5kzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Internet firewall data"
      ],
      "metadata": {
        "id": "V81GPFEk6eqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('firewall_data.zip'):\n",
        "    # If the file doesn't exist, download it\n",
        "  !pip install wget\n",
        "  !wget https://archive.ics.uci.edu/static/public/542/internet+firewall+data.zip -O firewall_data.zip\n",
        "  !unzip firewall_data.zip\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('log2.csv')\n",
        "\n",
        "# Drop any missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Encode the 'Action' column to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Action'] = label_encoder.fit_transform(data['Action'])\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop('Action', axis=1)\n",
        "y = data['Action']"
      ],
      "metadata": {
        "id": "2uBl3TKy5GtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(X, y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "y_valid = y_valid.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 4\n",
        "output_dim = len(label_encoder.classes_)  # Number of unique classes in 'Action'\n",
        "\n",
        "model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
        "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "3EcNdcRI-mMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, X_train_tensor, y_train_tensor, X_valid_tensor, y_valid_tensor)"
      ],
      "metadata": {
        "id": "v8l4eGQQ_adS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf91d3fd-4b0c-4ca3-e874-bdfa46386a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.1364, Training Accuracy: 0.9495, Valid Accuracy: 0.9475\n",
            "Epoch 2/10, Loss: 0.0415, Training Accuracy: 0.9749, Valid Accuracy: 0.9744\n",
            "Epoch 3/10, Loss: 0.0214, Training Accuracy: 0.9818, Valid Accuracy: 0.9818\n",
            "Epoch 4/10, Loss: 0.0151, Training Accuracy: 0.9848, Valid Accuracy: 0.9847\n",
            "Epoch 5/10, Loss: 0.0119, Training Accuracy: 0.9861, Valid Accuracy: 0.9866\n",
            "Epoch 6/10, Loss: 0.0102, Training Accuracy: 0.9872, Valid Accuracy: 0.9877\n",
            "Epoch 7/10, Loss: 0.0093, Training Accuracy: 0.9880, Valid Accuracy: 0.9882\n",
            "Epoch 8/10, Loss: 0.0085, Training Accuracy: 0.9881, Valid Accuracy: 0.9882\n",
            "Epoch 9/10, Loss: 0.0081, Training Accuracy: 0.9885, Valid Accuracy: 0.9886\n",
            "Epoch 10/10, Loss: 0.0079, Training Accuracy: 0.9888, Valid Accuracy: 0.9888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sports articles for objectivity analysis"
      ],
      "metadata": {
        "id": "aiMtlvb6QUwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('sports_data.zip'):\n",
        "    # If the file doesn't exist, download it\n",
        "  !pip install wget\n",
        "  !wget https://archive.ics.uci.edu/static/public/450/sports+articles+for+objectivity+analysis.zip -O sports_data.zip\n",
        "\n",
        "!pip install pandas lxml\n",
        "\n",
        "import pandas as pd\n",
        "if not os.path.exists('features.xls'):\n",
        "    !unzip sports_data.zip\n",
        "\n",
        "data = pd.read_xml('features.xls', parser='lxml', xpath='//ss:Cell')\n",
        "\n",
        "# Drop any missing values\n",
        "# data.dropna(inplace=True)\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "# Encode the 'Action' column to numerical values\n",
        "# label_encoder = LabelEncoder()\n",
        "# data['Action'] = label_encoder.fit_transform(data['Action'])\n",
        "\n",
        "# # Separate features and labels\n",
        "# X = data.drop('Action', axis=1)\n",
        "# y = data['Action']\n"
      ],
      "metadata": {
        "id": "gc4BrtFLCxGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "360eecf3-e024-42fc-f401-612f569a6f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XPathEvalError",
          "evalue": "Undefined namespace prefix",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXPathEvalError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-f0823d408191>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip sports_data.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features.xls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'//ss:Cell'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Drop any missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\u001b[0m in \u001b[0;36mread_xml\u001b[0;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mxpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for parser can only be lxml or etree.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m     \u001b[0mdata_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m     return _data_to_frame(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxml_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\u001b[0m in \u001b[0;36m_validate_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    590\u001b[0m         )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxml_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._Element.xpath\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/lxml/xpath.pxi\u001b[0m in \u001b[0;36mlxml.etree.XPathElementEvaluator.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/lxml/xpath.pxi\u001b[0m in \u001b[0;36mlxml.etree._XPathEvaluatorBase._handle_result\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mXPathEvalError\u001b[0m: Undefined namespace prefix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiaOcEUQTnpx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}